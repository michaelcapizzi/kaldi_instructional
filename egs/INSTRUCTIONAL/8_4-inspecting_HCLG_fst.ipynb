{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.4: Inspecting `HCLG.fst`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks we ran `run_compile_graph.sh` which built a large `FST` called `HCLG.fst`.  And since we ran this command for **each** of the three acoustic models we built, you will see an `HCLG.fst` in each of the three \"main\" subdirectories of `exp`: `monophones`, `triphones`, and `triphones_lda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah exp/monophones/graph/HCLG.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah exp/triphones/graph/HCLG.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah exp/triphones_lda/graph/HCLG.fst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you should notice is that, perhaps not surprisingly, the `HCLG` is larger for each of the subsequent levels of the acoustic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we inspect the `HCLG` in more detail, take the time to read [this **excellent** blog post](http://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html) (from one of the main contributors of `kaldi`) that describes in detail the makeup of the `HCLG`.  \n",
    "\n",
    "You'll also want to read **Section 6** of [this tutorial](https://github.com/michaelcapizzi/kaldi/blob/kaldi_instructional/egs/INSTRUCTIONAL/resource_files/resources/wfst_tutorial.pdf) which is a summary of the [original paper](https://github.com/michaelcapizzi/kaldi/blob/kaldi_instructional/egs/INSTRUCTIONAL/resource_files/resources/wfst_paper.pdf) introducing the idea of an `HCLG`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building `HCLG`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HCLG` is a single `FST` that represents **all** aspects of our `ASR` pipeline into one graph.  As you read, it is the `composition` of **four** separate `FST`s (Note that they are `composed` in reverse order.\n",
    "\n",
    "Decoding (when we take a new audio file and predict what was said) comes down to two steps:\n",
    "\n",
    "   1. determining which `GMM` best matches the incoming frames\n",
    "   2. looking for the most likely path through the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same packages we used last week to take a closer look at `HCLG` and its composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of the way `kaldi` installed `openFST` we have to add the path to the python functions here\n",
    "import sys\n",
    "sys.path.append(\"/scratch/kaldi/tools/openfst-1.6.2/lib/python2.7/site-packages\")    \n",
    "\n",
    "from utils.fst_manipulate import fst_manipulate as fstman  # scripts to further manipulate fsts\n",
    "\n",
    "import pywrapfst as openfst  # the wrapper module\n",
    "import graphviz as dot       # a wrapper for graphviz, which will allow us to visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $G$\n",
    "\n",
    "`G` is the `FST` representation of our `language model`.  We looked at this in detail in the last week's notebooks.  It has `word:word` on its edges.  Below is our `language model` built from the animal corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_animal = openfst.Fst.read(\"resource_files/fst/animal_fst-2_gram.fst\")\n",
    "G_animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"real\" `G.fst` can be found in `data/lang_test_tg` and was built way back in week 3 when we ran `run_prepare_data.sh` to build the `data` directory.\n",
    "\n",
    "**Note:** These composite `FST`s will be too big to visualize, but we can still gather some information about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah data/lang_test_tg/G.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = openfst.Fst.read(\"data/lang_test_tg/G.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the number of states by converting the `iterator` in `.states()` to a `<list>` and getting its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_states = len(list(G.states()))\n",
    "G_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a similar thing with the `.arcs()` `iterator` with a small modification.  `.arcs()` takes one argument, a `state`, and so we loop through all `state`s, and then count how many `arc`s that state has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_arcs = 0\n",
    "for s in G.states():\n",
    "    intermediate_arcs = len(list(G.arcs(s)))\n",
    "    G_arcs += intermediate_arcs\n",
    "G_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some quick functions to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_states(fst_in):\n",
    "    return len(list(fst_in.states()))\n",
    "\n",
    "def get_num_arcs(fst_in):\n",
    "    num_arcs = 0\n",
    "    for s in fst_in.states():\n",
    "        intermediate_arcs = len(list(fst_in.arcs(s)))\n",
    "        num_arcs += intermediate_arcs\n",
    "    return num_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get some information about the `arc`s.\n",
    "\n",
    "**Note:** We'll just look at the first **five** states and then `break` out of our nested `for` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for s in G.states():\n",
    "    for a in G.arcs(s):\n",
    "        if c < 5:\n",
    "            print(\"in: {}\\nout: {}\\nweight: {}\".format(\n",
    "                a.ilabel,\n",
    "                a.olabel,\n",
    "                a.weight\n",
    "                )\n",
    "            )\n",
    "            print(\"=========\")\n",
    "        else:\n",
    "            break\n",
    "        c += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `openfst` will use `index`es instead of `string`s on the `arc`s, but we can recover the words by looking at the \"lookup\" file `kaldi` built for this very purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/lang/words.txt | grep -E \" 2$\"       # the -E flag will allow us to use a regex\n",
    "cat data/lang/words.txt | grep -E \" 49$\"\n",
    "cat data/lang/words.txt | grep -E \" 220$\"\n",
    "cat data/lang/words.txt | grep -E \" 227$\"\n",
    "cat data/lang/words.txt | grep -E \" 456$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the `ilabel` and `olabel` are the same, confirming that the `arc`s consist of `word:word`.  And the `weight` is the representation of the probability (see `7.2 Examining G_fst`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L$\n",
    "`L` is the `FST` representation of our `lexicon`.  This was built in week 3 when we built the `data` directory (see `3.2: Inspecting data dir`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lah data/lang/ | grep L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = openfst.Fst.read(\"data/lang/L.fst\")\n",
    "print(\"number of states in L: {}\".format(get_num_states(L)))\n",
    "print(\"number of arcs in L: {}\".format(get_num_arcs(L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for s in L.states():\n",
    "    for a in L.arcs(s):\n",
    "        if c < 15:\n",
    "            print(\"in: {}\\nout: {}\\nweight: {}\".format(\n",
    "                a.ilabel,\n",
    "                a.olabel,\n",
    "                a.weight\n",
    "                )\n",
    "            )\n",
    "            print(\"=========\")\n",
    "        else:\n",
    "            break\n",
    "        c += 1\n",
    "    if c > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`L` has a different `arc` structure, consisting of `phone:word`.  And so to understand these `arc`s we need to also access the `phones` \"lookup\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/lang/phones.txt | grep -E \" 122$\"\n",
    "cat data/lang/words.txt | grep -E \" 8$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not clear what the `weight` represents, but you'll notice that it's almost always **the same** value (or 0).  So if the weight is equal for all `arc`s, it is essentially unimportant in determining shortest path.\n",
    "\n",
    "**Note:** You may also be wondering how this will work for words consisting of more than one phone.  The **first** `arc` will have `phone:word` and each subsequent arc will have `phone:<eps>` (`<eps>` representing $epsilon$, or the empty `arc`).  You can see an example of this in the visualization of $L$ in this [blog post](http://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $LG = L \\circ G$\n",
    "\n",
    "When we `compose` `L` and `G`, we will get a representation that incorporates **both** spelling **and** language model information.  We will end up with an `FST` that has the `arc` structure of `phone:word`.  \n",
    "\n",
    "**Note:** In general, a `composition` will keep the arc **`input`** of the first `FST` and the arc **`output`** of the second `FST`.\n",
    "\n",
    "If you did **NOT** delete the `tmp` folder in `data/lang_test_tg`, then you'll have a copy of an `LG.fst` built from the last `run_compile_graph.sh` command you ran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah data/lang_test_tg/tmp/LG.fst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shouldn't be surprising that it is **much** larger than `L` and `G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LG = openfst.Fst.read(\"data/lang_test_tg/tmp/LG.fst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for s in LG.states():\n",
    "    for a in LG.arcs(s):\n",
    "        if c < 10:\n",
    "            print(\"in: {}\\nout: {}\\nweight: {}\".format(\n",
    "                a.ilabel,\n",
    "                a.olabel,\n",
    "                a.weight\n",
    "                )\n",
    "            )\n",
    "            print(\"=========\")\n",
    "        else:\n",
    "            break\n",
    "        c += 1\n",
    "    if c > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/lang/phones.txt | grep -E \" 14$\"\n",
    "cat data/lang/words.txt | grep -E \" 79970$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And remember that the `arc` `weights` from $G$ represented the language model probabilities, so these are propogated to $LG$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $C$\n",
    "\n",
    "`C` is a representation of the `triphone` information from our acoustic model. \n",
    "\n",
    "**Note:** This `FST` isn't explicitly built in `kaldi` as a standalone item, and so we can't examine it like we did `G` and `L`.  But [this blog post](http://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html) has an image of what it looks like.  It also explains the indexing in a very straightforward manner:\n",
    "\n",
    " ```\n",
    " The input symbols of the C graph are triphone IDs, which are specified by using a Kaldi-specific data structure called ilabel_info(frankly clabel_info would have been more intuitive name for me, but perhaps there is reason it's called that way). Basically this is an array of arrays, where the the indices of the first dimension are the triphone IDs and the individual entries of the nested arrays are the IDs of the context-independent phones, which constitute the context window for the particular triphone. For example if there are triphone \"a/b/c\"(i.e. central phone \"b\" with left context \"a\" and right context \"c\") with id \"10\" the eleventh entry in the ilabel_info will be an array containing the context-independent ID's of the phones \"a\", \"b\" and \"c\".```\n",
    " \n",
    "So to simplify, the `arc` structure is `triphone:phone` where `phone` in this case refers to the `ARPAbet` `phones` we are using to represents our words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head data/lang/phones.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $CLG = C \\circ LG$\n",
    "\n",
    "Since this is a composition of `C` (`arc` structure of `triphone:phone`) and `LG` (`arc` structure of `phone:word`), the resulting `FST` will have `arc` structure of `triphone:word`.  And the `arc` `weight`s are again a propogation of our language model probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $H$\n",
    "\n",
    "Remember that our acoustic model is ultimately made up of an `HMM`, and so the `H` here incorporates that information into our graph.  Its `arc` structure is `transition_id:triphone` where `transition_id` consists of four parts:\n",
    " 1. a `phone`\n",
    " 2. an `HMM` `state`\n",
    " 3. a `PDF`\n",
    " 4. an `HMM` outgoing `arc`\n",
    " \n",
    " \n",
    "[This blog post](http://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html) gives an example:\n",
    "\n",
    "```\n",
    "For example \"k_1_739_1\" in this notation means that this is the transition-id associated with the state \"1\"(i.e. the second state) of the monophone \"k\" having PDF ID of 739(this is in general different for the different context-dependent versions of \"k\") and the outgoing arc from this HMM state, which has ID \"1\". \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $HCLG = H \\circ CLG$\n",
    "\n",
    "Our final graph is a composition of all four of the individual parts above.  And most importantly it has an `arc` structure of `transition_id:word`.  And this is **exactly** what we need in order to make predictions on new audio.  For any given frame, our `GMM` will make a prediction as to which `transition_id` to assign it, and given that information for each consecutive frame, we can work our way through the graph to make a prediction as to what `word`s are represented by the sequence of frames.\n",
    "\n",
    "**Note:** You'll actually see **both** an `HaCLG.fst` and an `HCLG.fst`.  The `HaCLG.fst` is simply an intermediate form (if you're really interested as to why it's required, it's explained briefly [here](http://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html)).  We are only going to pay attention to the **final** version: `HCLG.fst`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing `HCLG` from different acoustic models\n",
    "\n",
    "We have built **three** different `HCLG.fst`s:\n",
    " 1. one built from our `monophone` acoustic model\n",
    " 2. one built from our `triphone` acoustic model\n",
    " 3. one built from our `triphone_lda` acoustic model\n",
    "\n",
    "But they are different sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls -lah exp/monophones/graph/HCLG.fst\n",
    "ls -lah exp/triphones/graph/HCLG.fst\n",
    "ls -lah exp/triphones_lda/graph/HCLG.fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCLG_mono = openfst.Fst.read(\"exp/monophones/graph/HCLG.fst\")\n",
    "HCLG_tri = openfst.Fst.read(\"exp/triphones/graph/HCLG.fst\")\n",
    "HCLG_tri_lda = openfst.Fst.read(\"exp/triphones_lda/graph/HCLG.fst\")\n",
    "\n",
    "print(\"number of states compared\\nmono: {}\\ntri: {}\\ntri_lda: {}\\n\\n\".format(\n",
    "        get_num_states(HCLG_mono),\n",
    "        get_num_states(HCLG_tri),\n",
    "        get_num_states(HCLG_tri_lda)\n",
    "    )\n",
    ")\n",
    "print(\"====================\")\n",
    "print(\"number of arcs compared\\nmono: {}\\ntri: {}\\ntri_lda: {}\".format(\n",
    "        get_num_arcs(HCLG_mono),\n",
    "        get_num_arcs(HCLG_tri),\n",
    "        get_num_arcs(HCLG_tri_lda)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It **should** be clear that we used the **exact same** `L` and `G` for all three of these, and so the only things that could have **possibly** changed were the `C` and `H`, which makes sense since **both** of these individual `FST`s are built from parts of the acoustic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may remember from `6.4: Examining the acoustic models` that the `triphone` model actually had a **smaller** `decision tree` than the `monophone` model because it did some state-tying (*e.g.* clustering).  And you may also remember that the `triphone_lda` model had a **larger** `decision tree` than the `triphone` model because we increased the number of leaves that we would allow.  The number of leaves of the acoustic model `decision tree`s directly impact the size of `H` which explains the differences in the number of states for each `HCLG` above. \n",
    "\n",
    "These size differences will have an impact of the **time** it takes to decode a new audio sample...something we'll look at more in the next two weeks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
