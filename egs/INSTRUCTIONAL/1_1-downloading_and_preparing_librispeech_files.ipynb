{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1: Downloading and preparing `librispeech` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a free dataset consisting of readings from books available at `project gutenberg`.\n",
    "\n",
    "The language models and lexicons are explained [here](http://www.openslr.org/12/).\n",
    "\n",
    "Note: You do **not** need to download them yourself.  The scripts below will automatically download the necessary files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to download raw audio\n",
    "data=${KALDI_INSTRUCTIONAL_PATH}/raw_data\n",
    "mkdir $data\n",
    "\n",
    "# base url for downloads\n",
    "data_url=www.openslr.org/resources/12\n",
    "lm_url=www.openslr.org/resources/11\n",
    "\n",
    "# source files with path information\n",
    ". ${KALDI_INSTRUCTIONAL_PATH}/path.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audio files are explained [here](http://www.openslr.org/12/).  \n",
    "\n",
    "There are two sets of audio: `clean` and `other`.  `clean` is a subset of the audio that is very clearly articulated and \"easier\" to run through `ASR`.  `other` is a subset of data that is much more difficult to run through `ASR`.  There are also three different sized training sets: `100 hrs`, `360 hrs`, and `500 hrs`.  \n",
    "\n",
    "We will do all of our training on `train-clean-100`, and will test on *both* `test-clean` and `test-other`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will download the following audio subsets into the directory `INSTRUCTIONAL/raw_data`:\n",
    " - `train-clean-100`\n",
    " - `dev-clean`\n",
    " - `dev-other`\n",
    " - `test-clean`\n",
    " - `test-other`\n",
    "\n",
    "**Note:** This step could take quite a while (perhaps even > 1 hr) to complete (depending on your internet connection speed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dev-clean test-clean dev-other test-other train-clean-100; do\n",
    "    ${KALDI_INSTRUCTIONAL_PATH}/local/download_and_untar.sh ${data} ${data_url} ${part}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `ffmpeg` to `downsample` and `convert` the `librispeech` audio files from `16kHz flac` to `8kHz wav` (with `16-bit signed little endian encoding`).  \n",
    "\n",
    "We will also consolidate all the `train`, `dev`, and `test` audio subsets into respective, flat directories:\n",
    " - `train_clean_audio`\n",
    " - `dev_clean_audio`\n",
    " - `dev_other_audio`\n",
    " - `test_clean_audio`\n",
    " - `test_other_audio`\n",
    " \n",
    "**Note:** This step could take up to `1 hr` to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dev-clean test-clean dev-other test-other train-clean-100; do\n",
    "    ${KALDI_INSTRUCTIONAL_PATH}/utils/data/convert_audio_directory.sh \\\n",
    "        -i ${KALDI_INSTRUCTIONAL_PATH}/raw_data/LibriSpeech/${part} \\\n",
    "        -o ${KALDI_INSTRUCTIONAL_PATH}/raw_data/LibriSpeech/${part}_audio \\\n",
    "        -s 8000\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then another quick pass to clean up the filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dev-clean_audio test-clean_audio dev-other_audio test-other_audio train-clean-100_audio; do\n",
    "    ${KALDI_INSTRUCTIONAL_PATH}/utils/data/strip_duplicate_filetype.sh \\\n",
    "        ${KALDI_INSTRUCTIONAL_PATH}/raw_data/LibriSpeech/${part}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading `language model`s and `lexicon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the other files needed, `language model`s and `lexicon`, have already been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`librispeech-lm-norm.txt.gz` is a compressed file of the `text` used to build the language models. <br>\n",
    "`librispeech-lexicon.txt` is a file that contains all the words in the `ASR` vocabulary and their pronunciations. <br>\n",
    "`3-gram.arpa.gz` is a compressed `3-gram` `language model`. <br>\n",
    "`3-gram.pruned.1e-7.arpa.gz` and `3gram.pruned.3e-7.arpa.gz` are `prune`d versions of `3-gram.arpa.gz`. <br>\n",
    "`4-gram.arpa.gz` is a `4-gram` `language model`. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will download these files into the directory `INSTRUCTIONAL/raw_data`.\n",
    "\n",
    "**Note:** This step could take up to `1 hr` to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "${KALDI_INSTRUCTIONAL_PATH}/local/download_lm.sh ${lm_url} ${data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of later steps, we will uncompress the language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lm in 3-gram.arpa.gz 3-gram.pruned.1e-7.arpa.gz 3-gram.pruned.3e-7.arpa.gz 4-gram.arpa.gz; do\n",
    "    gzip -df raw_data/${lm}\n",
    "    echo \"uncompressed ${lm}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to remove some `symbolic links` created in a previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm raw_data/lm_*.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing bugs in `lexicon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two identical entries for `SPIRITS` in the `lexicon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat raw_data/librispeech-lexicon.txt | grep SPIRITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so we are going to replace the second entry with an alternative pronunciation (more about alternative pronunciations later):\n",
    "\n",
    "```\n",
    "SPIRITS  S P IH1 R IH1 T S\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat raw_data/librispeech-lexicon.txt | \\\n",
    "    perl -pe 's{S P IH1 R IH0 T S}{++$n == 4 ? \"S P IH1 R IH1 T S\" : $&}ge' \\\n",
    "    > raw_data/librispeech-lexicon.txt.corrected\n",
    "    \n",
    "mv raw_data/librispeech-lexicon.txt.corrected raw_data/librispeech-lexicon.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat raw_data/librispeech-lexicon.txt | grep SPIRITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kaldi` also expects that we have an entry for `<unk>` words to this `lexicon` (more about this later):\n",
    "\n",
    "```\n",
    "<unk>    SIL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printf \"<unk>\\tSIL\\n\" >> raw_data/librispeech-lexicon.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail -n3 raw_data/librispeech-lexicon.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a transcript file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script will generate a bunch of files, most of which we will ignore for now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dev-clean test-clean dev-other test-other train-clean-100; do\n",
    "    data_files=${data}/LibriSpeech/${part}_data\n",
    "    mkdir -p ${data_files}\n",
    "    ${KALDI_INSTRUCTIONAL_PATH}/local/data_prep.sh \\\n",
    "        ${data}/LibriSpeech/${part} \\\n",
    "        ${data_files}\n",
    "    rm -r ${data}/LibriSpeech/${part}    # we no longer need the original audio, so we can delete it\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but it will allow us to easily make a single file containing all the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in dev-clean test-clean dev-other test-other train-clean-100; do\n",
    "    data_files=${data}/LibriSpeech/${part}_data\n",
    "    cat ${data_files}/text\n",
    "done > ${data}/librispeech-transcripts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 raw_data/librispeech-transcripts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a phones file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following script will build a list of all the phones used in our lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python local/build_phones_list.py \\\n",
    "    ${data}/librispeech-lexicon.txt \\\n",
    "    ${data}/librispeech-phones.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head -n5 raw_data/librispeech-phones.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
